{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6a7a64",
   "metadata": {},
   "source": [
    "# Final Report\n",
    "## Clustering Analysis (with Regression modeling)\n",
    "### Brandyn Waterman, 4/8/2022, Innis Cohort\n",
    "Hello and welcome! Let's begin with the needed imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82e1cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe manipulations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modules needed to perform necessary functions\n",
    "import wrangle_zillow as w\n",
    "import explore as e\n",
    "\n",
    "# Turning off warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f6e76",
   "metadata": {},
   "source": [
    "## Overview:\n",
    "The purpose of this project is to assist in the prediction of log error for Zillow's Zestimate house value predictions. This will be done by:\n",
    "- Identifying some of the key drivers behind the log error\n",
    "- Applying these insights to regression models that can help predict the log error\n",
    "- Sharing learned insights to provide recommendations and solutions moving forward "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf215ca",
   "metadata": {},
   "source": [
    "### Planning:\n",
    "Prior to interacting with the data we want to lay out some of our intentions/initial questions:\n",
    "\n",
    "Some of the initial questions for the data: \n",
    "1. Do primary house attributes impact log error? (bedrooms, bathrooms, age, squarefeet)\n",
    "2. Do secondary house attributes impact log error? (num_fireplace, threequarter_baths, hottub_or_spa, has_pool)\n",
    "3. Does geography impact log error? (latitude, longitude, regionidzip, fips)\n",
    "4. Can we successfully use any of our features to cluster for log error predictions?\n",
    "    - Geographic clustering\n",
    "        - Latitude/Longitude\n",
    "    - Continuous feature clustering\n",
    "5. Does log error being positive or negative arise from any of the features?\n",
    "\n",
    "Some of the hypotheses to be explored:\n",
    "1. Is there a linear relationship between log error and our continuous features? (Pearsonr)\n",
    "2. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4851d35e",
   "metadata": {},
   "source": [
    "### Acquire:\n",
    "The wrangle_zillow.py module contains the functions used to acquire our data. The get_db_url() function assists in accessing the SQL server and then using a query and the acquire_zillow() function we gather the necessary data and store it in a dataframe. Our initial dataframe contains a number of columns that will be narrowed down through preparation and exploration of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe305bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached csv\n"
     ]
    }
   ],
   "source": [
    "# In our wrangle_zillow() module we use our acquire_zillow() function to gather the Zillow data from the SQL server\n",
    "zillow = w.acquire_zillow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0f7f7f",
   "metadata": {},
   "source": [
    "### Prepare:\n",
    "After acquiring our data we will need to do a fair bit of modification and or manipulation to make it wholly useful for our purposes. The following are the steps that were taken:\n",
    "1. Ensuring we are only working with single unit properties, utilizing identifiers from the SQL server\n",
    "2. Identifying a lack of proper data input for some columns and filling the nulls to signify better inputs\n",
    "    - Main data this was utilized for: fireplace, hottub/spa, pool, three quarter bath, tax delinquency\n",
    "3. Dropping leftover null values, and unwanted data (based on unusable or incorrect data inputs)\n",
    "    - This is done with all encompassing mechanisms (dropna()), non-null proportion requirements by row or column, and eliminating faulty data inputs (e.g. 0 bedrooms)\n",
    "4. Feature engineering age from yearbuilt data\n",
    "5. Ensuring columns are the correct data type\n",
    "6. Removal of outliers to make our outcomes as generally usable as possible\n",
    "7. Encoding our currently recognized categorical columns\n",
    "    - fips, hottub_or_spa, has_pool, tax_delinquency\n",
    "8. Renaming our columns for easier use\n",
    "9. Splitting our original dataframe into train, validate, and test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bb9edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our wrangle_zillow() module we use our prepare_zillow() function, with our acquired dataframe\n",
    "# We clean, prepare, and split the dataframe to produce train, validate, and test dataframes\n",
    "train, validate, test = w.prepare_zillow(zillow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91a8c80",
   "metadata": {},
   "source": [
    "### Explore:\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ebe231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will set our alpha for all of our statistical testing\n",
    "alpha = .05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7251ee",
   "metadata": {},
   "source": [
    "#### Question 1: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4db313c",
   "metadata": {},
   "source": [
    "#### Question 2: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339f8493",
   "metadata": {},
   "source": [
    "#### Question 3: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d373f6e",
   "metadata": {},
   "source": [
    "#### Question 4: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1c12c",
   "metadata": {},
   "source": [
    "#### Question 5: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af611942",
   "metadata": {},
   "source": [
    "### Scaling:\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c6c6d",
   "metadata": {},
   "source": [
    "### Clustering:\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5128422a",
   "metadata": {},
   "source": [
    "### Exploration Summary:\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e75978b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python397jvsc74a57bd038cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
